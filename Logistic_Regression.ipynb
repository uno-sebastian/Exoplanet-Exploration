{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data\n",
    "* Use MinMaxScaler to scale the numerical data.\n",
    "* Separate the data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_time0bk  \\\n",
       "0              0              0              0              0   170.538750   \n",
       "1              0              0              0              0   162.513840   \n",
       "2              0              1              0              0   175.850252   \n",
       "3              0              1              0              0   170.307565   \n",
       "4              0              0              0              0   171.595550   \n",
       "\n",
       "   koi_duration         ra        dec koi_disposition  \n",
       "0       2.95750  291.93423  48.141651       CONFIRMED  \n",
       "1       4.50700  291.93423  48.141651       CONFIRMED  \n",
       "2       1.78220  297.00482  48.134129  FALSE POSITIVE  \n",
       "3       2.40641  285.53461  48.285210  FALSE POSITIVE  \n",
       "4       1.65450  288.75488  48.226200       CONFIRMED  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data\n",
    "training_df = pd.read_csv(\"Data/Cleaned_Data.csv\") \n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = \"koi_disposition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9564, 8) (9564,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X = training_df.drop(columns=[target_feature])\n",
    "y = training_df[[target_feature]].values.ravel() \n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data to better train\n",
    "def scale_data(X, X_train, X_test):\n",
    "    X_scaler = MinMaxScaler().fit(X)\n",
    "    # apply the scale to training and testing data sets\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    #\n",
    "    return X_train_scaled, X_test_scaled, X_scaler\n",
    "\n",
    "X_train, X_test, X_scaler = scale_data(X, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, penalty='l1', solver='liblinear', tol=0.01,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    dual=False,\n",
    "    tol=0.01,\n",
    "    C=1.0,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    solver='liblinear',\n",
    "    max_iter=500,\n",
    "    multi_class='auto',\n",
    "    verbose=2\n",
    ")\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, penalty='l1', solver='liblinear', tol=0.01,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7759654259026907\n",
      "Testing Data Score: 0.767043078209954\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic_Regression_Classifier.sav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, \"Logistic_Regression_Classifier.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Model Parameters\n",
    "* Use GridSearch to tune model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    classifier, \n",
    "    {\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "        \"tol\": [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "        \"C\": [0.1, 0.5, 1, 5, 10, 50],\n",
    "        \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "        \"max_iter\": [100, 500, 1000]\n",
    "    }, \n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score: 0.7775007167883992\n",
      "Grid best penalty: l1\n",
      "Grid best tol: 0.01\n",
      "Grid best C: 1\n",
      "Grid best solver: liblinear\n",
      "Grid best max_Iter: 500\n",
      "Training Data Score: 0.7766624843161857\n",
      "Testing Data Score: 0.767461313258051\n"
     ]
    }
   ],
   "source": [
    "print(f\"Grid best score: {grid.best_score_}\")\n",
    "print(f\"Grid best penalty: {grid.best_estimator_.penalty}\")\n",
    "print(f\"Grid best tol: {grid.best_estimator_.tol}\")\n",
    "print(f\"Grid best C: {grid.best_estimator_.C}\")\n",
    "print(f\"Grid best solver: {grid.best_estimator_.solver}\")\n",
    "print(f\"Grid best max_Iter: {grid.best_estimator_.max_iter}\")\n",
    "\n",
    "print(f\"Training Data Score: {grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonAdv",
   "language": "python",
   "name": "pythonadv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
